{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import multiprocessing\nmultiprocessing.cpu_count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install albumentations > /dev/null\n!pip install -U segmentation-models\n#!pip install -U efficientnet\nimport numpy as np\nimport pandas as pd\nimport gc\nimport keras\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\n\nfrom skimage.transform import resize\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.losses import binary_crossentropy\n\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import  ModelCheckpoint\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\nfrom keras.layers import Conv2D, Concatenate, MaxPooling2D\nfrom keras.layers import UpSampling2D, Dropout, BatchNormalization\nfrom tqdm import tqdm_notebook\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras.utils import conv_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.engine.topology import get_source_inputs\nfrom keras.engine import InputSpec\nfrom keras import backend as K\nfrom keras.layers import LeakyReLU\nfrom keras.layers import ZeroPadding2D\nfrom keras.losses import binary_crossentropy\nimport keras.callbacks as callbacks\nfrom keras.callbacks import Callback\nfrom keras.applications.xception import Xception\nfrom keras.layers import multiply\n\n\nfrom keras import optimizers\nfrom keras.legacy import interfaces\nfrom keras.utils.generic_utils import get_custom_objects\n\nfrom keras.engine.topology import Input\nfrom keras.engine.training import Model\nfrom keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\nfrom keras.layers.core import Activation, SpatialDropout2D\nfrom keras.layers.merge import concatenate\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.regularizers import l2\nfrom keras.layers.core import Dense, Lambda\nfrom keras.layers.merge import concatenate, add\nfrom keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\nfrom keras.optimizers import SGD,Adam\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport glob\nimport shutil\nimport os\nimport random\nfrom PIL import Image\nimport cv2\n\nseed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\n    \n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_mask_fn = glob.glob('/kaggle/input/siimacr-pneumothorax-segmentation-data-256/masks/*')\nmask_df = pd.DataFrame()\nmask_df['file_names'] = all_mask_fn\nmask_df['mask_percentage'] = 0\nmask_df.set_index('file_names',inplace=True)\nfor fn in all_mask_fn:\n    mask_df.loc[fn,'mask_percentage'] = np.array(Image.open(fn)).sum()/(256*256*255) #255 is bcz img range is 255\n    \nmask_df.reset_index(inplace=True)\nsns.distplot(mask_df.mask_percentage)\nmask_df['labels'] = 0\nmask_df.loc[mask_df.mask_percentage>0,'labels'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_df.to_csv('data.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_label_map = {i : j for i,j in zip(mask_df.file_names.values,mask_df.labels.values)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df,val_df = train_test_split(mask_df,test_size = 0.15,stratify = mask_df.labels,random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('No. of train files:', len(train_df))\nprint('No. of val files:', len(val_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_filepath = train_df['file_names'].tolist()\nval_filepath = val_df['file_names'].tolist()\ntrain_im_path = 'train'\ntrain_mask_path = 'masks'\nimg_size = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma,OneOf,\n    ToFloat, ShiftScaleRotate,GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise,CenterCrop,\n    IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion,RandomSizedCrop\n)\ntrain_augment = Compose([\n    HorizontalFlip(p = 0.5),\n    ShiftScaleRotate(p = 0.5),\n    #ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03,p = 0.5),\n    OneOf([\n        RandomContrast(),\n        RandomGamma(),\n        RandomBrightness(),\n         ], p=0.3),\n    OneOf([\n        RandomSizedCrop(min_max_height=(176, 256), height=256, width=256,p=0.25),\n        CLAHE(clip_limit=2.0, tile_grid_size=(32,32),p = 0.4),\n         ], p=0.5),\n    ToFloat()\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    \n    def __init__(self,filepath = train_filepath,train_im_path = train_im_path,train_mask_path = train_mask_path,\n                 augmentations = None,img_size = img_size,batch_size = 64,nchannels = 3,shuffle = True):\n        \n        self.train_im_paths = list(filepath)\n        self.train_im_path = train_im_path\n        self.train_mask_path = train_mask_path\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.nchannels = nchannels\n        self.shuffle = shuffle\n        self.augmentations = augmentations\n        self.on_epoch_end()\n    \n    def __len__(self):\n        \n        return int(np.ceil(len(self.train_im_paths)/ self.batch_size))\n    \n    def __getitem__(self,index):\n        \n        indexes = self.indexes[index * self.batch_size : min((index + 1) * self.batch_size, len(self.train_im_paths))]\n        list_im_ids = [self.train_im_paths[i] for i in indexes]\n        X,y = self.data_generation(list_im_ids)\n        \n        if(self.augmentations is None):\n            return np.array(X,dtype = 'float32'),np.array(y) / 255\n        \n        im,mask = [],[]\n        for x,y in zip(X,y):\n            augmented = self.augmentations(image = x,mask = y)\n            im.append(augmented['image'])\n            mask.append(augmented['mask'])\n        return np.array(im,dtype = 'float32'),np.array(mask) / 255\n    \n    def on_epoch_end(self):\n        \n        self.indexes = np.arange(len(self.train_im_paths))\n        if(self.shuffle):\n            np.random.shuffle(self.indexes)\n    \n    def data_generation(self,list_im_ids):\n        \n        X = np.empty((len(list_im_ids),self.img_size,self.img_size,self.nchannels))\n        y = np.empty((len(list_im_ids),self.img_size,self.img_size,1))\n        for i,mask_path in enumerate(list_im_ids):\n            #print(mask_path)\n            mask = np.array(Image.open(mask_path))\n            #plt.imshow(mask)\n            img_path = mask_path.replace(self.train_mask_path,self.train_im_path)\n            img = cv2.imread(img_path)\n#             lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n\n#             lab_planes = cv2.split(lab)\n\n#             clahe = cv2.createCLAHE(clipLimit=3.0,tileGridSize=(32,32))\n\n#             lab_planes[0] = clahe.apply(lab_planes[0])\n\n#             lab = cv2.merge(lab_planes)\n\n#             img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n#             img = np.true_divide(img,255.)\n            #plt.imshow(img,cmap = 'bone')\n            if(len(img.shape) == 2):\n                img = np.repeat(img[...,np.newaxis],3,2)\n            \n           # plt.imshow(img,cmap = 'bone')\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size))\n            y[i,] = cv2.resize(mask,(self.img_size,self.img_size))[...,np.newaxis]\n            y[y > 0] = 255\n        return np.uint8(X),np.uint8(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = DataGenerator(batch_size=64,shuffle=False,augmentations=train_augment)\nimages,masks = a.__getitem__(0)\nmax_images = 64\ngrid_width = 16\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n\nfor i,(im, mask) in enumerate(zip(images,masks)):\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(im.squeeze(), cmap=\"bone\")\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"Reds\")    \n    ax.axis('off')\nplt.suptitle(\"Chest X-rays, Red: Pneumothorax.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n    return c, p\n\ndef up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    us = keras.layers.UpSampling2D((2, 2))(x)\n    concat = keras.layers.Concatenate()([us, skip])\n    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    return c\n\ndef bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    return c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def UNet(image_size):\n    f = [16, 32, 64, 128, 256]\n    inputs = keras.layers.Input((image_size, image_size, 3))\n    \n    p0 = inputs\n    c1, p1 = down_block(p0, f[0]) #128 -> 64\n    c2, p2 = down_block(p1, f[1]) #64 -> 32\n    c3, p3 = down_block(p2, f[2]) #32 -> 16\n    c4, p4 = down_block(p3, f[3]) #16->8\n    \n    bn = bottleneck(p4, f[4])\n    \n    u1 = up_block(bn, c4, f[3]) #8 -> 16\n    u2 = up_block(u1, c3, f[2]) #16 -> 32\n    u3 = up_block(u2, c2, f[1]) #32 -> 64\n    u4 = up_block(u3, c1, f[0]) #64 -> 128\n    \n    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n    model = keras.models.Model(inputs, outputs)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = BatchNormalization()(x)\n    if activation == True:\n        x = LeakyReLU(alpha=0.1)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = LeakyReLU(alpha=0.1)(blockInput)\n    x = BatchNormalization()(x)\n    blockInput = BatchNormalization()(blockInput)\n    x = convolution_block(x, num_filters, (3,3))\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# backbone = Xception(input_shape=(512,512,3),weights='imagenet',include_top=False)\n# input = backbone.input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def UXception(input_shape=(None, None, 3),dropout_rate=0.5):\n\n    backbone = Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n    input = backbone.input\n    start_neurons = 16\n\n    conv4 = backbone.layers[121].output\n    conv4 = LeakyReLU(alpha=0.1)(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(dropout_rate)(pool4)\n    \n     # Middle\n    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = LeakyReLU(alpha=0.1)(convm)\n    \n    deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(dropout_rate)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n    \n    deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    conv3 = backbone.layers[31].output\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(dropout_rate)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n\n    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    conv2 = backbone.layers[21].output\n    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)\n    uconv2 = concatenate([deconv2, conv2])\n        \n    uconv2 = Dropout(0.1)(uconv2)\n    uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n    \n    deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    conv1 = backbone.layers[11].output\n    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1)\n    uconv1 = concatenate([deconv1, conv1])\n    \n    uconv1 = Dropout(0.1)(uconv1)\n    uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n    \n    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n    uconv0 = Dropout(dropout_rate)(uconv0)\n    uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n    \n    uconv0 = Dropout(dropout_rate/2)(uconv0)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n    \n    model = Model(input, output_layer)\n    model.name = 'u-xception'\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #img_size = 256\n# model = UXception(input_shape=(img_size,img_size,3))\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import segmentation_models as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sm.Unet('seresnet34', input_shape=(img_size,img_size,3), encoder_weights='imagenet',decoder_block_type='transpose')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SWA(keras.callbacks.Callback):\n    \n    def __init__(self, filepath, swa_epoch):\n        super(SWA, self).__init__()\n        self.filepath = filepath\n        self.swa_epoch = swa_epoch \n    \n    def on_train_begin(self, logs=None):\n        self.nb_epoch = self.params['epochs']\n        print('Stochastic weight averaging selected for last {} epochs.'\n              .format(self.nb_epoch - self.swa_epoch))\n        \n    def on_epoch_end(self, epoch, logs=None):\n        \n        if epoch == self.swa_epoch:\n            self.swa_weights = self.model.get_weights()\n            \n        elif epoch > self.swa_epoch:    \n            for i in range(len(self.swa_weights)):\n                self.swa_weights[i] = (self.swa_weights[i] * \n                    (epoch - self.swa_epoch) + self.model.get_weights()[i])/((epoch - self.swa_epoch)  + 1)  \n\n        else:\n            pass\n        \n    def on_train_end(self, logs=None):\n        self.model.set_weights(self.swa_weights)\n        print('Final model parameters set to stochastic weight average.')\n        self.model.save_weights(self.filepath)\n        print('Final stochastic averaged weights saved to file.')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SnapshotCallbackBuilder:\n    \"\"\"Callback builder for snapshot ensemble training of a model.\n    From the paper \"Snapshot Ensembles: Train 1, Get M For Free\" (\n    https://openreview.net/pdf?id=BJYwwY9ll)\n    Creates a list of callbacks, which are provided when training a model\n    so as to save the model weights at certain epochs, and then sharply\n    increase the learning rate.\n    \"\"\"\n\n    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.01):\n        \"\"\"\n        Initialize a snapshot callback builder.\n        # Arguments:\n            nb_epochs: total number of epochs that the model will be trained for.\n            nb_snapshots: number of times the weights of the model will be saved.\n            init_lr: initial learning rate\n        \"\"\"\n        self.T = nb_epochs\n        self.M = nb_snapshots\n        self.alpha_zero = init_lr\n\n    def get_callbacks(self, model_prefix='Model'):\n\n        callback_list = [\n            callbacks.ModelCheckpoint(\"./keras.model\",monitor='val_iou_metric', \n                                   mode = 'max', save_best_only=True, verbose=1),\n            swa,\n            callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)\n        ]\n\n        return callback_list\n\n    def _cosine_anneal_schedule(self, t):\n        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.\n        cos_inner /= self.T // self.M\n        cos_out = np.cos(cos_inner) + 1\n        return float(self.alpha_zero / 2 * cos_out)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_iou_vector(A,B):\n    batch_size = A.shape[0]\n    metric = 0.0\n    for i in range(batch_size):\n        t,p = A[i],B[i]\n        #print(t.dtype)\n        p = tf.dtypes.cast(p, tf.float32)\n        intersection = np.sum(t * p)\n        true = np.sum(t)\n        pred = np.sum(p)\n        \n        if(true == 0):\n            metric += (pred == 0)\n            \n        union = true + pred - intersection\n        iou = intersection / union\n        iou = np.floor(max(0,(iou - 0.45) * 20)) / 10\n        metric += iou\n    return metric / batch_size\ndef iou_metric(label,pred):\n    return tf.py_function(get_iou_vector,[label,pred > 0.5],tf.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coeff(y_true,y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred),0.5),'float32')\n    intersection = K.sum(y_true_f * y_pred_f)\n    dice_coeff = (intersection * 2) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return dice_coeff\ndef dice_loss(y_true,y_pred):   \n    smooth = 1\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    dice_coeff = (intersection * 2 + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1 - dice_coeff\ndef bce_dice_loss(y_true,y_pred):\n    return binary_crossentropy(y_true,y_pred) + dice_loss(y_true,y_pred)\ndef bce_logdice_loss(y_true,y_pred):\n    return binary_crossentropy(y_true,y_pred) - K.log(1. - dice_loss(y_true,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.compile(loss = sm.losses.bce_jaccard_loss,optimizer = SGD(learning_rate = 0.0001, momentum=0.0, nesterov=False),metrics = [sm.metrics.iou_score])\nmodel.compile(loss=bce_dice_loss, optimizer='adam', metrics=[iou_metric])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_filepath = train_df['file_names'].tolist()\nval_filepath = val_df['file_names'].tolist()\ntrain_im_path = 'train'\ntrain_mask_path = 'masks'\nepochs = 110\nsnapshot = SnapshotCallbackBuilder(nb_epochs = epochs,nb_snapshots = 1, init_lr = 1e-3)\nswa = SWA('./keras_swa.model',106)\nbatch_size = 64\ntrain_generator = DataGenerator(filepath = train_filepath, augmentations=train_augment, batch_size = batch_size)\nval_generator = DataGenerator(filepath = val_filepath, augmentations=train_augment, batch_size = batch_size)\nhistory = model.fit_generator(train_generator,validation_data = val_generator,epochs = epochs,callbacks = snapshot.get_callbacks())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,4))\nplt.subplot(1,2,1)\nplt.plot(history.history['iou_metric'][1:])\nplt.plot(history.history['val_iou_metric'][1:])\nplt.ylabel('iou')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='lower right')\n\nplt.title('model IOU')\nplt.savefig('iou.png')\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'][1:])\nplt.plot(history.history['val_loss'][1:])\nplt.ylabel('val_loss')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='upper right')\nplt.title('model loss')\nplt.savefig('loss.png')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    print('using swa weight model')\n    model.load_weights('./keras_swa.model')\nexcept Exception as e:\n    print(e)\n    model.load_weights('./keras.model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_result(model,validation_generator,img_size): \n    # TBD predict both orginal and reflect x\n    preds_test1 = model.predict_generator(validation_generator).reshape(-1, img_size, img_size)\n    return preds_test1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_augment_flipped = Compose([\n    HorizontalFlip(),\n    ToFloat()\n])\nval_augment = Compose([\n    ToFloat()\n])\nvalidation_generator = DataGenerator(filepath = val_filepath, augmentations=val_augment, batch_size = batch_size, shuffle = False)\nvalidation_generator_flipped = DataGenerator(filepath = val_filepath, augmentations=val_augment_flipped, batch_size = batch_size,  shuffle = False)\nval_preds_flipped = predict_result(model,validation_generator_flipped, img_size)\nval_preds = predict_result(model,validation_generator, img_size)\nval_preds = 0.5 * val_preds_flipped + 0.5 * val_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold_best = 0.5\nmax_images = 64\ngrid_width = 16\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n\nvalidation_generator = DataGenerator(filepath = val_filepath, augmentations=val_augment, batch_size = 64, shuffle = False)\n\nimages,masks = validation_generator.__getitem__(0)\nfor i,(im, mask) in enumerate(zip(images,masks)):\n    pred = val_preds[i]\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(im[...,0], cmap=\"bone\")\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"Reds\")    \n    ax.imshow(np.array(np.round(pred > threshold_best), dtype=np.float32), alpha=0.5, cmap=\"Greens\")\n    ax.axis('off')\nplt.suptitle(\"Green:Prediction , Red: Pneumothorax.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)\n\n#valid_fn = glob.glob('./keras_mask_val/*')\ny_valid_ori = np.array([cv2.resize(np.array(Image.open(fn)),(img_size,img_size)) for fn in val_filepath])\nassert y_valid_ori.shape == val_preds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholds = np.linspace(0.2, 0.9, 31)\nious = np.array([iou_metric_batch(y_valid_ori, np.int32(val_preds > threshold)) for threshold in tqdm_notebook(thresholds)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_images = 64\ngrid_width = 16\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n\n# validation_generator = DataGenerator(train_im_path = valid_im_path ,\n#                                      train_mask_path=valid_mask_path,augmentations=AUGMENTATIONS_TEST,\n#                                      img_size=img_size,batch_size=64,shuffle=False)\nvalidation_generator = DataGenerator(filepath = val_filepath, augmentations=val_augment, batch_size = 64, shuffle = False)\n\nimages,masks = validation_generator.__getitem__(0)\nfor i,(im, mask) in enumerate(zip(images,masks)):\n    pred = val_preds[i]\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(im[...,0], cmap=\"bone\")\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"Reds\")    \n    ax.imshow(np.array(np.round(pred > threshold_best), dtype=np.float32), alpha=0.5, cmap=\"Greens\")\n    ax.axis('off')\nplt.suptitle(\"Green:Prediction , Red: Pneumothorax.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_fn = glob.glob('/kaggle/input/siimacr-pneumothorax-segmentation-data-256/test/*')\nx_test = [cv2.resize(np.array(Image.open(fn)),(img_size,img_size)) for fn in test_fn]\nx_test = np.array(x_test)\nx_test = np.array([np.repeat(im[...,None],3,2) for im in x_test])\nprint(x_test.shape)\npreds_test_orig = model.predict(x_test,batch_size=batch_size)\n\nx_test = np.array([np.fliplr(x) for x in x_test])\npreds_test_flipped = model.predict(x_test,batch_size=batch_size)\npreds_test_flipped = np.array([np.fliplr(x) for x in preds_test_flipped])\n\npreds_test = 0.5*preds_test_orig + 0.5*preds_test_flipped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_images = 64\ngrid_width = 16\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n# for i, idx in enumerate(index_val[:max_images]):\nfor i, idx in enumerate(test_fn[:max_images]):\n    img = x_test[i]\n    pred = preds_test[i].squeeze()\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(img, cmap=\"Greys\")\n    ax.imshow(np.array(np.round(pred > threshold_best).T, dtype=np.float32), alpha=0.5, cmap=\"Reds\")\n    ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ndef mask2rle(img, width, height):\n    rle = []\n    lastColor = 0;\n    currentPixel = 0;\n    runStart = -1;\n    runLength = 0;\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 255:\n                    runStart = currentPixel;\n                    runLength = 1;\n                else:\n                    rle.append(str(runStart));\n                    rle.append(str(runLength));\n                    runStart = -1;\n                    runLength = 0;\n                    currentPixel = 0;\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor;\n            currentPixel+=1;\n\n    return \" \".join(rle)\n\ndef rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 255\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n\n#from mask_functions import rle2mask,mask2rle\nimport pdb\n\n# Generate rle encodings (images are first converted to the original size)\nrles = []\ni,max_img = 1,10\nplt.figure(figsize=(16,4))\nfor p in tqdm_notebook(preds_test):\n    p = p.squeeze()\n    im = cv2.resize(p,(1024,1024))\n    im = im > threshold_best\n#     zero out the smaller regions.\n    if im.sum()<1024*2:\n        im[:] = 0\n    im = (im.T*255).astype(np.uint8)  \n    rles.append(mask2rle(im, 1024, 1024))\n    i += 1\n    if i<max_img:\n        plt.subplot(1,max_img,i)\n        plt.imshow(im)\n        plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = [o.split('/')[-1][:-4] for o in test_fn]\nsub_df = pd.DataFrame({'ImageId': ids, 'EncodedPixels': rles})\nsub_df.loc[sub_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.environ['KAGGLE_USERNAME'] = \"aaryapatel98\"\nos.environ['KAGGLE_KEY'] = \"75398e02b13a492c8a28ed09e05930e7\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!kaggle competitions submit siim-acr-pneumothorax-segmentation -f submission.csv -m \"My submission message\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}