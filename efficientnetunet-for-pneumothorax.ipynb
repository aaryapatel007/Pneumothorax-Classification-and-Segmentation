{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install albumentations > /dev/null\n!pip install -U segmentation-models\n!pip install -U efficientnet\nimport numpy as np\nimport pandas as pd\nimport gc\nimport keras\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\n\nfrom skimage.transform import resize\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.losses import binary_crossentropy\n\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import  ModelCheckpoint\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\nfrom keras.layers import Conv2D, Concatenate, MaxPooling2D\nfrom keras.layers import UpSampling2D, Dropout, BatchNormalization\nfrom tqdm import tqdm_notebook\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras.utils import conv_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.engine.topology import get_source_inputs\nfrom keras.engine import InputSpec\nfrom keras import backend as K\nfrom keras.layers import LeakyReLU\nfrom keras.layers import ZeroPadding2D\nfrom keras.losses import binary_crossentropy\nimport keras.callbacks as callbacks\nfrom keras.callbacks import Callback\nfrom keras.applications.xception import Xception\nfrom keras.layers import multiply\n\n\nfrom keras import optimizers\nfrom keras.legacy import interfaces\nfrom keras.utils.generic_utils import get_custom_objects\nimport segmentation_models as sm\nfrom keras.engine.topology import Input\nfrom keras.engine.training import Model\nfrom keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\nfrom keras.layers.core import Activation, SpatialDropout2D\nfrom keras.layers.merge import concatenate\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.regularizers import l2\nfrom keras.layers.core import Dense, Lambda\nfrom keras.layers.merge import concatenate, add\nfrom keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\nfrom keras.optimizers import SGD,Adam\nfrom keras.models import Model,load_model\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport glob\nimport shutil\nimport os\nimport random\nfrom PIL import Image\nimport cv2\nfrom random import shuffle\nseed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\n    \n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Dataframe containing file_path, mask percentage and corresponding label(pneumothorax or no pneumothorax)"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_mask_fn = glob.glob('/kaggle/input/siimacr-pneumothorax-segmentation-data-512/masks/*')\nmask_df = pd.DataFrame()\nmask_df['file_names'] = all_mask_fn\nmask_df['mask_percentage'] = 0\nmask_df.set_index('file_names',inplace=True)\nfor fn in all_mask_fn:\n    mask_df.loc[fn,'mask_percentage'] = np.array(Image.open(fn)).sum()/(512*512*255) #255 is bcz img range is 255\n    \nmask_df.reset_index(inplace=True)\nsns.distplot(mask_df.mask_percentage)\nmask_df['labels'] = 0\nmask_df.loc[mask_df.mask_percentage>0,'labels'] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-test splitting of 85%-15%"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df,val_df = train_test_split(mask_df,test_size = 0.15,stratify = mask_df.labels,random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('No. of train files:', len(train_df))\nprint('No. of val files:', len(val_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_filepath = train_df['file_names'].tolist()\nval_filepath = val_df['file_names'].tolist()\ntrain_im_path = 'train'\ntrain_mask_path = 'masks'\nimg_size = 512","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding Augmentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma,OneOf,\n    ToFloat, ShiftScaleRotate,GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise,CenterCrop,\n    IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion,RandomSizedCrop\n)\ntrain_augment = Compose([\n    HorizontalFlip(p = 0.5),\n    ShiftScaleRotate(p = 0.5),\n    #ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03,p = 0.5),\n    OneOf([\n        RandomContrast(),\n        RandomGamma(),\n        RandomBrightness(),\n         ], p=0.3),\n    RandomSizedCrop(min_max_height=(176, 256), height=512, width=512,p=0.25),\n    ToFloat()\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DataGenerator Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    \n    def __init__(self,filepath = train_filepath,train_im_path = train_im_path,train_mask_path = train_mask_path,\n                 augmentations = None,img_size = img_size,batch_size = 64,nchannels = 3,shuffle = True):\n        \n        self.train_im_paths = list(filepath)\n        self.train_im_path = train_im_path\n        self.train_mask_path = train_mask_path\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.nchannels = nchannels\n        self.shuffle = shuffle\n        self.augmentations = augmentations\n        self.on_epoch_end()\n    \n    def __len__(self):\n        \n        return int(np.ceil(len(self.train_im_paths)/ self.batch_size))\n    \n    def __getitem__(self,index):\n        \n        indexes = self.indexes[index * self.batch_size : min((index + 1) * self.batch_size, len(self.train_im_paths))]\n        list_im_ids = [self.train_im_paths[i] for i in indexes]\n        X,y = self.data_generation(list_im_ids)\n        \n        if(self.augmentations is None):\n            return np.array(X,dtype = 'float32'),np.array(y) / 255\n        \n        im,mask = [],[]\n        for x,y in zip(X,y):\n            augmented = self.augmentations(image = x,mask = y)\n            im.append(augmented['image'])\n            mask.append(augmented['mask'])\n        return np.array(im,dtype = 'float32'),np.array(mask) / 255\n    \n    def on_epoch_end(self):\n        \n        self.indexes = np.arange(len(self.train_im_paths))\n        if(self.shuffle):\n            np.random.shuffle(self.indexes)\n    \n    def data_generation(self,list_im_ids):\n        \n        X = np.empty((len(list_im_ids),self.img_size,self.img_size,self.nchannels))\n        y = np.empty((len(list_im_ids),self.img_size,self.img_size,1))\n        for i,mask_path in enumerate(list_im_ids):\n            #print(mask_path)\n            mask = np.array(Image.open(mask_path))\n            #plt.imshow(mask)\n            img_path = mask_path.replace(self.train_mask_path,self.train_im_path)\n            img = cv2.imread(img_path)\n\n            if(len(img.shape) == 2):\n                img = np.repeat(img[...,np.newaxis],3,2)\n            \n           # plt.imshow(img,cmap = 'bone')\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size))\n            y[i,] = cv2.resize(mask,(self.img_size,self.img_size))[...,np.newaxis]\n            y[y > 0] = 255\n        return np.uint8(X),np.uint8(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing the Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = DataGenerator(batch_size=64,shuffle=False,augmentations=train_augment)\nimages,masks = a.__getitem__(0)\nmax_images = 64\ngrid_width = 16\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width,grid_height))\n\nfor i,(im, mask) in enumerate(zip(images,masks)):\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(im.squeeze(), cmap=\"bone\")\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"Reds\")    \n    ax.axis('off')\nplt.suptitle(\"Chest X-rays, Masks\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EfficientUNet model code"},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet.keras import EfficientNetB4\n\ndef UEfficientNet(input_shape=(None, None, 3),dropout_rate=0.1):\n\n    backbone = EfficientNetB4(weights='imagenet',\n                            include_top=False,\n                            input_shape=input_shape)\n    input = backbone.input\n    start_neurons = 8\n\n    conv4 = backbone.layers[342].output\n    conv4 = LeakyReLU(alpha=0.1)(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(dropout_rate)(pool4)\n    \n     # Middle\n    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\",name='conv_middle')(pool4)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = LeakyReLU(alpha=0.1)(convm)\n    \n    deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    deconv4_up1 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4)\n    deconv4_up2 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4_up1)\n    deconv4_up3 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4_up2)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(dropout_rate)(uconv4) \n    \n    uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n#     uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = LeakyReLU(alpha=0.1)(uconv4)  #conv1_2\n    \n    deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    deconv3_up1 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(deconv3)\n    deconv3_up2 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(deconv3_up1)\n    conv3 = backbone.layers[154].output\n    uconv3 = concatenate([deconv3,deconv4_up1, conv3])    \n    uconv3 = Dropout(dropout_rate)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n#     uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n\n    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    deconv2_up1 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(deconv2)\n    conv2 = backbone.layers[92].output\n    uconv2 = concatenate([deconv2,deconv3_up1,deconv4_up2, conv2])\n        \n    uconv2 = Dropout(0.1)(uconv2)\n    uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n#     uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n    \n    deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    conv1 = backbone.layers[30].output\n    uconv1 = concatenate([deconv1,deconv2_up1,deconv3_up2,deconv4_up3, conv1])\n    \n    uconv1 = Dropout(0.1)(uconv1)\n    uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n#     uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n    \n    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n    uconv0 = Dropout(0.1)(uconv0)\n    uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n#     uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n    \n    uconv0 = Dropout(dropout_rate/2)(uconv0)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n    \n    model = Model(input, output_layer)\n    model.name = 'u-efficient'\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sm.Unet('efficientnetb4', input_shape=(img_size,img_size,3), encoder_weights='imagenet',decoder_block_type='transpose')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stochatic Weight Averaging Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SWA(keras.callbacks.Callback):\n    \n    def __init__(self, filepath, swa_epoch):\n        super(SWA, self).__init__()\n        self.filepath = filepath\n        self.swa_epoch = swa_epoch \n    \n    def on_train_begin(self, logs=None):\n        self.nb_epoch = self.params['epochs']\n        print('Stochastic weight averaging selected for last {} epochs.'\n              .format(self.nb_epoch - self.swa_epoch))\n        \n    def on_epoch_end(self, epoch, logs=None):\n        \n        if epoch == self.swa_epoch:\n            self.swa_weights = self.model.get_weights()\n            \n        elif epoch > self.swa_epoch:    \n            for i in range(len(self.swa_weights)):\n                self.swa_weights[i] = (self.swa_weights[i] * \n                    (epoch - self.swa_epoch) + self.model.get_weights()[i])/((epoch - self.swa_epoch)  + 1)  \n\n        else:\n            pass\n        \n    def on_train_end(self, logs=None):\n        self.model.set_weights(self.swa_weights)\n        print('Final model parameters set to stochastic weight average.')\n        self.model.save_weights(self.filepath)\n        print('Final stochastic averaged weights saved to file.')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cosine Annealing Learning Rate Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SnapshotCallbackBuilder:\n\n    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.01):\n        \n        self.T = nb_epochs\n        self.M = nb_snapshots\n        self.alpha_zero = init_lr\n\n    def get_callbacks(self, model_prefix='Model'):\n\n        callback_list = [\n            callbacks.ModelCheckpoint(\"./keras.model\",monitor='val_iou_metric', \n                                   mode = 'max', save_best_only=True, verbose=1),\n            swa,\n            callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)\n        ]\n\n        return callback_list\n\n    def _cosine_anneal_schedule(self, t):\n        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.\n        cos_inner /= self.T // self.M\n        cos_out = np.cos(cos_inner) + 1\n        return float(self.alpha_zero / 2 * cos_out)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IOU Evaluation Metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_iou_vector(A,B):\n    batch_size = A.shape[0]\n    metric = 0.0\n    for i in range(batch_size):\n        t,p = A[i],B[i]\n        #print(t.dtype)\n        p = tf.dtypes.cast(p, tf.float32)\n        intersection = np.sum(t * p)\n        true = np.sum(t)\n        pred = np.sum(p)\n        \n        if(true == 0):\n            metric += (pred == 0)\n            \n        union = true + pred - intersection\n        iou = intersection / union\n        iou = np.floor(max(0,(iou - 0.45) * 20)) / 10\n        metric += iou\n    return metric / batch_size\ndef iou_metric(label,pred):\n    return tf.py_function(get_iou_vector,[label,pred > 0.5],tf.float64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Dice Coefficient and Dice loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coeff(y_true,y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred),0.5),'float32')\n    intersection = K.sum(y_true_f * y_pred_f)\n    dice_coeff = (intersection * 2) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return dice_coeff\ndef dice_loss(y_true,y_pred):   \n    smooth = 1\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    dice_coeff = (intersection * 2 + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1 - dice_coeff\ndef bce_dice_loss(y_true,y_pred):\n    return binary_crossentropy(y_true,y_pred) + dice_loss(y_true,y_pred)\ndef bce_logdice_loss(y_true,y_pred):\n    return binary_crossentropy(y_true,y_pred) - K.log(1. - dice_loss(y_true,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compiling the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.compile(loss = sm.losses.bce_jaccard_loss,optimizer = SGD(learning_rate = 0.0001, momentum=0.0, nesterov=False),metrics = [sm.metrics.iou_score])\nmodel.compile(loss=bce_dice_loss, optimizer='adam', metrics=[iou_metric])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Code"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_filepath = train_df['file_names'].tolist()\nval_filepath = val_df['file_names'].tolist()\ntrain_im_path = 'train'\ntrain_mask_path = 'masks'\nepochs = 50\nsnapshot = SnapshotCallbackBuilder(nb_epochs = epochs,nb_snapshots = 1, init_lr = 1e-3)\nswa = SWA('./keras_swa.model',epochs - 3)\nbatch_size = 8\ntrain_generator = DataGenerator(filepath = train_filepath, augmentations=train_augment, batch_size = batch_size)\nval_generator = DataGenerator(filepath = val_filepath, augmentations=train_augment, batch_size = batch_size)\nhistory = model.fit_generator(train_generator,validation_data = val_generator,epochs = epochs,callbacks = snapshot.get_callbacks())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,4))\nplt.subplot(1,2,1)\nplt.plot(history.history['iou_metric'][1:])\nplt.plot(history.history['val_iou_metric'][1:])\nplt.ylabel('iou')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='lower right')\n\nplt.title('model IOU')\nplt.savefig('iou.png')\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'][1:])\nplt.plot(history.history['val_loss'][1:])\nplt.ylabel('val_loss')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='upper right')\nplt.title('model loss')\nplt.savefig('loss.png')\ngc.collect()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}